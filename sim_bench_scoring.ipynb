{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T17:46:17.234476Z",
     "start_time": "2025-11-14T17:46:17.231084Z"
    }
   },
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "import decoupler as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.stats import rankdata\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate simulated data\n",
    "!uv run src/sim_data_generator_optimized.py simulated_data/parameters.json"
   ],
   "id": "510cc0417fe51b61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:33:25.619875Z",
     "start_time": "2025-11-14T17:33:19.822914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run kale without weights\n",
    "print(\"\\nRunning KALE for test case\")\n",
    "!uv run src/kale.py --gene_exp_file simulated_data/simulated_scRNASeq_data.tsv --prior_file simulated_data/simulated_prior_data.tsv --output_file simulated_data/_kale_scores_test1.tsv --pvalue_output_file simulated_data/_kale_pvalues_test1.tsv --ignore_zeros False --cores 8 --method rank_of_ranks --min_targets 1 --weighted False"
   ],
   "id": "f54a1a9ea1213ade",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running KALE for test case\n",
      "Using raw gene expression as input for per-cell ranking...\r\n",
      "Starting TF activity using 8 cores.\r\n",
      "Running in parallel with CORES_USED=8.\r\n",
      "Processing cells in parallel:   0%|                    | 0/2000 [00:00<?, ?it/s][Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\r\n",
      "Processing cells in parallel:   1%|           | 16/2000 [00:01<02:08, 15.48it/s][Parallel(n_jobs=8)]: Done   34 out of 2000 | elapsed:    1.1s\r\n",
      "Processing cells in parallel: 100%|███████| 2000/2000 [00:01<00:00, 1199.68it/s]\r\n",
      "[Parallel(n_jobs=8)]: Done 1824 out of 2000 | elapsed:    2.2s\r\n",
      "[Parallel(n_jobs=8)]: Done 1985 out of 2000 | elapsed:    2.3s remaining:    0.0s\r\n",
      "[Parallel(n_jobs=8)]: Done 2000 out of 2000 | elapsed:    2.3s finished\r\n",
      "\r\n",
      "Aggregating results...\r\n",
      "kale completed\r\n",
      "Kale TF activity scores and p-values have been saved.\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:33:49.835111Z",
     "start_time": "2025-11-14T17:33:30.615095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run with a weighted option 2 with power factor 1\n",
    "print(\"\\nRunning KALE with weights for test case\")\n",
    "!uv run src/kale.py --gene_exp_file simulated_data/simulated_scRNASeq_data.tsv --prior_file simulated_data/simulated_prior_data.tsv --output_file simulated_data/_kale_scores_test2.tsv --pvalue_output_file simulated_data/_kale_pvalues_test2.tsv --ignore_zeros False --cores 8 --method rank_of_ranks --min_targets 1 --weighted True --weighted_power_factor 1"
   ],
   "id": "66dd56ea3eeb5990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running KALE with weights for test case\n",
      "Using raw gene expression as input for per-cell ranking...\r\n",
      "Calculating weighted gene expression as input for per-cell ranking...\r\n",
      "Starting TF activity using 8 cores.\r\n",
      "Running in parallel with CORES_USED=8.\r\n",
      "Processing cells in parallel:   0%|                    | 0/2000 [00:00<?, ?it/s][Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\r\n",
      "Processing cells in parallel:   2%|▏          | 40/2000 [00:01<00:43, 45.23it/s][Parallel(n_jobs=8)]: Done   34 out of 2000 | elapsed:    1.1s\r\n",
      "Processing cells in parallel:  52%|████▏   | 1040/2000 [00:04<00:03, 292.64it/s][Parallel(n_jobs=8)]: Done  976 out of 2000 | elapsed:    4.5s\r\n",
      "Processing cells in parallel: 100%|████████| 2000/2000 [00:07<00:00, 263.20it/s]\r\n",
      "[Parallel(n_jobs=8)]: Done 2000 out of 2000 | elapsed:    8.0s finished\r\n",
      "\r\n",
      "Aggregating results...\r\n",
      "kale completed\r\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "Refining TF activity scores with dynamic weighting based on initial results...\r\n",
      "Using raw gene expression as input for per-cell ranking...\r\n",
      "Calculating weighted gene expression as input for per-cell ranking...\r\n",
      "Starting TF activity using 8 cores.\r\n",
      "Running in parallel with CORES_USED=8.\r\n",
      "Processing cells in parallel:   0%|                    | 0/2000 [00:00<?, ?it/s][Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\r\n",
      "Processing cells in parallel:   6%|▌        | 112/2000 [00:00<00:05, 376.01it/s][Parallel(n_jobs=8)]: Done   56 out of 2000 | elapsed:    0.3s\r\n",
      "Processing cells in parallel:  63%|█████   | 1264/2000 [00:04<00:02, 284.52it/s][Parallel(n_jobs=8)]: Done 1200 out of 2000 | elapsed:    4.4s\r\n",
      "Processing cells in parallel: 100%|████████| 2000/2000 [00:07<00:00, 278.85it/s]\r\n",
      "[Parallel(n_jobs=8)]: Done 2000 out of 2000 | elapsed:    7.7s finished\r\n",
      "\r\n",
      "Aggregating results...\r\n",
      "kale completed\r\n",
      "Kale TF activity scores and p-values have been saved.\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:36:41.590586Z",
     "start_time": "2025-11-14T17:36:34.839266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Prior Knowledge Network\n",
    "net_file = \"simulated_data/simulated_prior_data.tsv\"\n",
    "effect_map = {\"upregulates-expression\": 1, \"downregulates-expression\": -1}\n",
    "net = pd.read_csv(\n",
    "    net_file,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"source\", \"weight\", \"target\"],\n",
    "    usecols=[0, 1, 2],\n",
    "    converters={\"weight\": effect_map.get}\n",
    ")[[\"source\", \"target\", \"weight\"]]\n",
    "\n",
    "\n",
    "# 4. Gene Expression data\n",
    "gene_exp_file = \"simulated_data/simulated_scRNASeq_data.tsv\"\n",
    "gene_exp = pd.read_csv(gene_exp_file, sep=\"\\t\", index_col=0)\n",
    "adata = sc.AnnData(gene_exp)\n",
    "\n",
    "\n",
    "methods_to_run = [\"viper\", \"mlm\"]\n",
    "dc.mt.decouple(adata, net, tmin=1, methods=methods_to_run)"
   ],
   "id": "4542e6fc71911b87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved viper scores to simulated_data/_viper_scores_simulated_data.tsv\n",
      "Saved mlm scores to simulated_data/_mlm_scores_simulated_data.tsv\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:45:14.135614Z",
     "start_time": "2025-11-14T17:45:14.130092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "viper_scores_df = adata.obsm[f\"score_viper\"]\n",
    "mlm_scores_df = adata.obsm[f\"score_mlm\"]"
   ],
   "id": "fb2d60ce7d64347a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:31:14.039271Z",
     "start_time": "2025-11-14T18:31:13.900668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kale_scores_df1 = pd.read_csv(\"simulated_data/_kale_scores_test1.tsv\", sep=\"\\t\", index_col=0)\n",
    "kale_scores_df2 = pd.read_csv(\"simulated_data/_kale_scores_test2.tsv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "print(kale_scores_df1.isna().sum().sum())\n",
    "print(kale_scores_df2.isna().sum().sum())"
   ],
   "id": "f67598abe26b5b91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:47:34.900009Z",
     "start_time": "2025-11-14T17:47:34.872736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfs = kale_scores_df1.columns.unique().tolist()\n",
    "cells = kale_scores_df1.index.unique().tolist()\n",
    "\n",
    "result = {}\n",
    "\n",
    "for tf in tfs:\n",
    "    kale_scores = pd.DataFrame(kale_scores_df1[tf], index=cells).sort_values(by=tf, ascending=True)\n",
    "    viper_scores = pd.DataFrame(viper_scores_df[tf], index=cells).sort_values(by=tf, ascending=True)\n",
    "    mlm_scores = pd.DataFrame(mlm_scores_df[tf], index=cells).sort_values(by=tf, ascending=True)\n",
    "    kale_scores2 = pd.DataFrame(kale_scores_df2[tf], index=cells).sort_values(by=tf, ascending=True)\n",
    "\n",
    "    kale_scores[\"marked\"] = True\n",
    "    viper_scores[\"marked\"] = True\n",
    "    mlm_scores[\"marked\"] = True\n",
    "    kale_scores2[\"marked\"] = True\n",
    "\n",
    "    # Rank the scores between 0 and 1\n",
    "    kale_scores['rank'] = (rankdata(kale_scores[tf], method='average') - 0.5) / len(kale_scores)\n",
    "    viper_scores['rank'] = (rankdata(viper_scores[tf], method='average') - 0.5) / len(viper_scores)\n",
    "    mlm_scores['rank'] = (rankdata(mlm_scores[tf], method='average') - 0.5) / len(mlm_scores)\n",
    "    kale_scores2['rank'] = (rankdata(kale_scores2[tf], method='average') - 0.5) / len(kale_scores2)\n",
    "\n",
    "    # Calculated mean rank of marked cells\n",
    "    mean_rank_kale = kale_scores[kale_scores['marked'] == True]['rank'].mean()\n",
    "    mean_rank_viper = viper_scores[viper_scores['marked'] == True]['rank'].mean()\n",
    "    mean_rank_mlm = mlm_scores[mlm_scores['marked'] == True]['rank'].mean()\n",
    "    mean_rank_kale2 = kale_scores2[kale_scores2['marked'] == True]['rank'].mean()\n",
    "\n",
    "    print(f\"{tf} ------------------------------\")\n",
    "    print(f\"\\tKALE Mean rank: {mean_rank_kale}\")\n",
    "    print(f\"\\tViper Mean rank: {mean_rank_viper}\")\n",
    "    print(f\"\\tMLM Mean rank: {mean_rank_mlm}\")\n",
    "    print(f\"\\tKALE with weights Mean rank: {mean_rank_kale2}\")\n",
    "\n",
    "    break"
   ],
   "id": "123296da31990f0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_1 ------------------------------\n",
      "\tKALE Mean rank: 0.5\n",
      "\tViper Mean rank: 0.5\n",
      "\tMLM Mean rank: 0.5\n",
      "\tKALE with weights Mean rank: 0.5\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "kale_scores"
   ],
   "id": "902ab531477221c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
